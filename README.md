# ğŸ“Š  Data Science Tasks

This repository contains completed tasks for the **CODTECH Internship**, focused on Data Cleaning (ETL) and Deep Learning (MNIST image classification) using Python.

---


## âœ… Task 1 â€“ ETL Pipeline (Task1)

### ğŸ“Œ Overview
Build an ETL (Extract, Transform, Load) pipeline to load data from a CSV, clean and preprocess it, and save the processed CSV for downstream analysis or modeling.

### ğŸ“‚ Files
- `Task1/data.csv` â€” raw input data
- `Task1/etl_pipeline.py` â€” ETL script (reads `data.csv`, preprocesses, writes `processed_data.csv`)
- `Task1/processed_data.csv` â€” output (generated after running the script)

### ğŸ›  Dependencies
- pandas
- numpy
- scikit-learn

Install: `pip install pandas numpy scikit-learn`

### â–¶ï¸ Run
From the repository root:
```bash
python Task1/etl_pipeline.py
```
The script will read `Task1/data.csv` and write `Task1/processed_data.csv`.

---

## âœ… Task 2 â€“ Deep Learning (MNIST)

### ğŸ“Œ Overview
Train a simple neural network on the MNIST handwritten digits dataset using TensorFlow/Keras. The script trains the model, evaluates it, and saves accuracy/loss plots to `Task2/results/`.

### ğŸ“‚ Files
- `Task2/model.py` â€” training script (creates `Task2/results/` automatically)
- `Task2/results/accuracy.png` â€” training vs. validation accuracy plot
- `Task2/results/loss.png` â€” training vs. validation loss plot

### ğŸ›  Dependencies
- tensorflow
- matplotlib
- numpy

Install: `pip install tensorflow matplotlib numpy`

### â–¶ï¸ Run
From the repository root:
```bash
python Task2/model.py
```
Note: training can take several minutes depending on your machine. The script creates the `Task2/results/` directory if it does not exist.

---

## ğŸ“ Notes & Recommendations
- Use a virtual environment (venv or conda) to isolate dependencies.
- Consider adding `requirements.txt` files in each task directory for reproducibility.
- Optionally add `if __name__ == "__main__":` guards to scripts to avoid running on import.

---

If you'd like, I can also:
- Create `requirements.txt` files for each task âœ…
- Add a short CI workflow to run fast smoke tests ğŸ”§
- Add example outputs or short screenshots to the README ğŸ“¸

---

#  Task 3 â€“ End-to-End Data Science Project

## Project Title:
House Price Prediction Web Application

## Description:
This project demonstrates a complete end-to-end data science workflow including:
- Data collection
- Data preprocessing
- Feature engineering
- Machine learning model training
- Model deployment using Flask

A trained machine learning model predicts house prices based on user input features through a web interface.

## Objectives:
- Build a complete data science pipeline
- Train and evaluate a machine l

## Project Structure:
Task3/
â”‚
â”œâ”€â”€ data/
â”‚ â””â”€â”€ housing.csv
â”‚
â”œâ”€â”€ model/
â”‚ â””â”€â”€ model.pkl
â”‚
â”œâ”€â”€ templates/
â”‚ â””â”€â”€ index.html
â”‚
â”œâ”€â”€ train_model.py
â”œâ”€â”€ app.py
â”œâ”€â”€ requirements.txt


## Workflow:
1. Data Loading
2. Data Preprocessing
3. Feature Encoding
4. Train-Test Splitting
5. Model Training
6. Model Saving
7. Flask API Development
8. Web App Deployment

## Installation & Execution:

### Step 1: Clone Repository
git clone <your-github-repository-link>

### Step 2: Create Virtual Environment
python -m venv .venv


### Step 3: Activate Virtual Environment
.venv\Scripts\activate


### Step 4: Install Dependencies
pip install -r requirements.txt


### Step 5: Train Model
python train_model.py


### Step 6: Run Flask Application
python app.py


Open browser and visit:
http://127.0.0.1:5000

# Task 4  
## Optimization Model using Linear Programming and Python

This project is part of the ** Internship Program â€“ Task 4**, where the objective is to solve a real-world **business optimization problem** using **Linear Programming techniques** and Python libraries such as **PuLP**.

---

## ğŸ“Œ Problem Statement

A manufacturing company produces two products: **Product A** and **Product B**.  
Each product requires machine time and labor time. The company wants to determine the **optimal number of units to produce** in order to **maximize total profit**, subject to limited resources.

---

## ğŸ¯ Objective

To **maximize profit** while efficiently utilizing:
- Machine hours
- Labor hours  

using **Linear Programming optimization techniques**.

---

## ğŸ§® Mathematical Model

Let:  
- x = units of Product A  
- y = units of Product B  

### Maximize:
40x + 30y


### Subject to constraints:
2x + y â‰¤ 40 (Machine hours)
x + 2y â‰¤ 60 (Labor hours)
x â‰¥ 0, y â‰¥ 0


---

## ğŸ›  Tools & Technologies Used

- Python  
- VS Code  
- Jupyter Notebook  
- PuLP (Linear Programming Library)  

---

## ğŸ“‚ Project Files

TASK4_OPTIMIZATION
â”‚
â”œâ”€â”€ optimization.ipynb # Main notebook
â””â”€â”€ requirements.txt # Required Python libraries


---

## ğŸš€ How to Run the Project

### 1ï¸âƒ£ Install Dependencies
```bash
pip install -r requirements.txt

ğŸ“Š Output
Status: Optimal
Product A units: 6.67
Product B units: 26.67
Maximum Profit = â‚¹1466.67
